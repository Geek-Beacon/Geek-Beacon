"use strict";(self.webpackChunkgeekbeacon_docs=self.webpackChunkgeekbeacon_docs||[]).push([[477],{10:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"docker_guide","metadata":{"permalink":"/blog/docker_guide","source":"@site/blog/2020-05-18-docker_guide.md","title":"Docker Guide Part 1","description":"Preamble","date":"2020-05-18T00:00:00.000Z","formattedDate":"May 18, 2020","tags":[{"label":"engineering","permalink":"/blog/tags/engineering"},{"label":"docker","permalink":"/blog/tags/docker"}],"readingTime":23.15,"truncated":true,"authors":[{"name":"lhz","title":"Docker Guide Part 1","url":"https://github.com/insanitywholesale","imageURL":"https://avatars3.githubusercontent.com/u/45580420?s=460&u=292dddc5e11159cd72839eb622f785db3952edaf&v=4"}],"frontMatter":{"slug":"docker_guide","title":"Docker Guide Part 1","author":"lhz","author_title":"Docker Guide Part 1","author_url":"https://github.com/insanitywholesale","author_image_url":"https://avatars3.githubusercontent.com/u/45580420?s=460&u=292dddc5e11159cd72839eb622f785db3952edaf&v=4","tags":["engineering","docker"]},"nextItem":{"title":"Welcome","permalink":"/blog/welcome"}},"content":"## Preamble\\n\\nDocker is quite popular and has a lot of benefits if used appropriately.\\nThis tutorial will hopefully help readers become more familiar with it.\\nYou snooze, you lose so let\'s get into it.\\n\\n## Prerequisites\\n\\n- MUST:\\n\\t- Have Linux installed\\n\\t- Have docker installed\\n\\t- Internet connection to download images\\n\\t- Some Linux knowledge\\n- OPTIONAL:\\n\\t- Dockerhub account to push images to\\n\\n\x3c!--truncate--\x3e\\n## Concepts and Architecture\\n\\n\\n### Images and Containers\\n\\nWhat are images, what are containers and how are they different?\\nImages are a snapshot of a system while containers are a running instance of an image.\\nFor example, the nginx docker image has all the necessary bits installed to run nginx.\\nWhen we start that image, there is now an nginx container running.\\n\\nTo see it action, we can run  \\n`docker image ls`  \\nto see all docker images on our system.\\nTo download a new one, also referred to as pulling an image, we can run\\n`docker pull nginx`  \\nor if a specific version is required,  \\n`docker pull nginx:1.17.10`\\n\\nImages are also immutable meaning they don\'t keep any changes you make to them.\\nIf we were to go into an ubuntu container, run `apt update && apt -y full-upgrade` then restart the container, the updates would be lost.\\nTo demonstrate it, we can run  \\n`docker run --rm -i -t ubuntu`  \\nthen when we see the shell prompt change, run  \\n`touch testfile && ls`  \\nfollowed up by `exit`.\\nRunning  \\n`docker run --rm -i -t ubuntu`  \\nagain followed up by `ls` shows that the file named `testfile` does not exist there anymore.\\nThe interactive shell won\'t really come up again until we get to debugging. Unlike virtual machines, containers are not meant to be used interactively.\\n\\n- Some notes so far:\\n\\t- The `--rm` removes the container when the docker command exits (not necessary here but good for testing so we don\'t fill up our system with unneeded containers)\\n\\t- The `-i -t` gives us an interactive terminal to execute commands in this case (this is not available on every image, for example postgres and nginx show logs\\n\\t\\t- In the case of nginx and postgres, even without (`-it`) they capture the terminal with logging so we use `-d` to run them in detached mode\\n\\t\\t- The `--name` option gives a (hopefully) human-readable name to the container, especially useful when used with `-d`\\n\\t- docker pulls the image we specified (in this case the ubuntu one) if it\'s not on the system yet when we use `docker run`\\n\\t- There is a special image named `scratch` if you want to build things from the lowest level allowable\\n\\nContainers can be started and stopped but it\'s more complex than that as is evident from our experimentation and notes this far.\\nWe\'ll return to using nginx now since most images are going to be centered around the included application.\\nUsing  \\n`docker run -d --name ngx-alp nginx:alpine`  \\nwe start an alpine-based nginx container running in detached mode.  \\nAfter checking the output of  \\n`docker container ls`  \\nspecifically the NAMES column, we can see that it did indeed start and was assigned the desired name.\\nA quick  \\n`docker stop ngx-alp`  \\nwill make it disappear from `docker container ls` but not from everywhere.\\nIf we try to run  \\n`docker run -d --name ngx-alp nginx:alpine`  \\nthen docker will return an error since there is a container with that name but in stopped state.\\nWe can confirm that using  \\n` docker container ls --all`  \\nand then choose to start it again using  \\n`docker start ngx-alp`  \\nor remove it using  \\n`docker rm ngx-alp`  \\nRemember, we didn\'t use `--rm` so the container did not get automatically removed after we stopped it.\\nYou might have figured it out already but the containers are given random unique names as well as a unique ID, both of which can be used to address them when we want to stop, start or remove them.\\n\\n### Tags\\n\\nWhat is the `:1.17.10` I added to the pull command in the previous section?\\nClearly it\'s a version number but more importantly it\'s an image tag.\\nTags allow us to specify the flavour or edition of the image that we want to use.\\nFor example, to pull an alpine-based nginx image, we can run\\n`docker pull nginx:1.17.10`  \\nor\\n`docker pull nginx:1.17.10-alpine`  \\nto be more explicit.\\nIf none is specified, the `:latest` tag is used so it is the default tag, keep this in mind.\\nImages can have multiple tags so `nginx:latest` and `nginx:1.17.10`(at the time of writing) will pull the same image but that won\'t be true forever.\\nExplicitly specifying tags is useful to avoid the \\"works on my machine\\" type of issues when working with docker.\\n\\n### Ports\\n\\nMany applications communicate over ports so how do we deal with that communication and move further along with our nginx example.\\nThe port required for a basic \\"this works\\" page to load from nginx is 80. However, if you were to run `docker run nginx` and try to\\n`curl http://localhost:80`  \\nit would not work.\\nFor an analogy with more conventional setups, think of it as port forwarding being required.\\nPort 80 inside the container needs to be mapped to a port on the system in order to become accessible which is controlled by the `-p` option.\\nI will use distinct ports to make the example more clear so here we go, run\\n`docker run -d -p --name ngx 3000:80 nginx`  \\n(which will use ``nginx:latest`) and then run  \\n`curl http://localhost:3000`  \\nThis should return a bit of HTML and internal CSS to indicate that the default nginx page is reachable.\\nWe see that port 3000 outside of the container is mapped to port 80 inside of the container.\\nTo make sure, we can try\\n`docker run -d -p --name ngx2 4000:80 nginx`  \\nand then\\n`curl http://localhost:4000`  \\nto see that it works and try\\n`docker run -d -p --name ngx2 3000:80 nginx`  \\nto check that it won\'t allow us to start it since port 3000 is already used by another container.\\n\\n### Networking\\n\\nFrom the get-go, docker has a bridge network that all containers connect to by default but don\'t have the perks of name resolution like user-defined bridge networks do.\\nWhat is a bridge network though and are there other types of networks?  \\nWe\'ll go through them one by one and explain what they\'re useful for.\\n\\n\\n#### Bridge\\nFirst, bridge networks. By utilizing NAT, in a similar way that a router does, they are able to have containers communicate over them (or not for security reasons). Each container connected to a bridge network gets its own IP address and there are iptables rules added to block or allow traffic between networks and containers (or ports as we saw in the previous section). While the default bridge network that docker creates is mostly fine for testing and messing around, user-defined networks have a few advantages that make them suitable for more proper use such as:  \\n\\t- DNS resolution to make containers able to communicate using names and not IPs which could change\\n\\t- Isolation since a container has to be explicitly added to them\\n\\t- Adding and removing a container can be done on the fly (without starting and stopping)\\n\\t- Configurability such as using a larger MTU and in general tweaking them for the use case\\n\\t- Sharing environment variables\\n\\t- Have effectively all ports exposed between them\\n\\t- Not having to use the deprecated `--link` flag  \\nSo it\'s safe to say that using user-defined ones is worth it. How to go about it then?\\nTime to find out.  \\nIn order to create a network we just have to run\\n`docker network create bridge-net`\\nor  \\n`docker network create --driver bridge bridge-net`  \\nand to delete it we use  \\n`docker network rm bridge-net`  \\nbut how do we use it?  \\nFor this, we\'ll need two containers. Let\'s pick alpine since it includes the `ping` command. The flag to specify what network to attach the container to is `--network` so the full commands are as follows\\n```\\ndocker run -dit --name alpine1 --network bridge-net alpine:latest\\ndocker run -dit --name alpine2 --network bridge-net alpine:latest\\n```\\nThe above will run two containers in detached mode and enable the interactive terminal. We can connect to that terminal,  \\n`docker attach alpine1`  \\nafter which we get a prompt inside it.\\nLet\'s test out that name resolution by pinging it 3 times  \\n`ping -c 3 alpine2`  \\nwhich should work wonderfully. This means our containers can talk to eachother using their names while also having randomly assigned addresses from docker\'s subnet.\\nIn case we forget the network\'s details, it is possible to use\\n`docker network list`  \\nto find the network\'s name followed by\\n`docker inspect bridge-net`\\nand get the network\'s details in JSON format.\\n\\n#### Macvlan\\n\\nWhen integration with the network that the host is connected to is desired, we can use macvlan. Despite VLAN being a part of the name, using them is an option rather than a requirement. Let\'s start with the possibly more familiar mode.  \\n\\n##### Bridge mode\\n\\nIn this mode, the network is bridged to a physical interface on the host and it integrates with the underlying network.\\n\\nTo see it in action, (I\'ll assume a fairly standard home network scheme) we can look at\\n```\\n$ ip r\\ndefault via 192.168.1.1 dev eth0 metric 2\\n172.16.0.0/16 dev virbr0 proto kernel scope link src 172.16.0.1 linkdown\\n172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown\\n172.18.0.0/16 dev br-b0ed5d210b62 proto kernel scope link src 172.18.0.1\\n192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.2\\n```\\nto find our interface\'s name, `eth0` in this case and then create the network\\n`docker network create -d macvlan --subnet=192.168.1.0/24 --gateway=192.168.1.1 -o parent=eth0 macvlan-net`  \\nConnecting containers to it is done the same way we previously used. For example,\\n`docker run -dit --name alpine-on-macvlan --network macvlan-net alpine:latest`\\n\\n##### 802.1q mode\\n\\nI\'m not going to go too in-depth about this mode since the amount of people with level 2 or level 3 managed switches is limited but it deserves at least a brief mention. If you\'ve worked with VLANS on linux, you know that new interfaces are created, usually in the format the name of the physical parent followed by a dot `.` and then the VLAN number. To create a network linked to VLAN 31 on the `eth0` interface, we use the same command as before but with a VLAN interface instead like so\\n`docker network create -d macvlan --subnet=192.168.1.0/24 --gateway=192.168.1.1 -o parent=eth0.31 macvlan31-net`\\n\\n[//]: # (maybe include host networking too)\\n\\n### Storage\\n\\nSo far we have not looked into how we work with storing data.  \\nIn the beginning it was stated and demonstrated that any changes made do not persist.\\nHow do people use containers to run file servers and databases then?\\nThe answer is bind mounts and volumes.\\nBind mounts map a specified directory on the host to one inside the container.\\nVolumes on the other hand are managed through docker and are a bit more isolated from the host\'s functionality.\\nEvery time we ran a container, an anonymous volume was created.\\nInstead, we could have created a named volume using\\n`docker volume create ngx-vol`  \\n`docker run --name ngx-with-vol -p 3000:80 --mount source=ngx-vol,target=/usr/share/nginx/html nginx`  \\nThe volumes are under `/var/lib/docker/volumes` in case you were wondering.\\nVolumes can be shared between two containers and be mounted read-only but we won\'t be going into that right now.\\nWith bind mounts, it looks a bit different since we need to pick a directory on the host.\\nIf the directory doesn\'t exist it will be created for us by docker.\\nLet\'s try it using  \\n`docker run --name ngx-with-bind-mount -p 3000:80 -v /tmp/ngx:/usr/share/nginx/html nginx`  \\nwhich will mount /tmp/ngx from the host to /usr/share/nginx/html in the container.\\nThis gives us an error if we try to\\n`curl http://localhost:3000`  \\nbecause the bind mounted host directory doesn\'t get filled with the contents of the container\'s target directory.\\nThere is an alternative syntax for this using the `--mount` option which is as follows  \\n`docker run -d --rm --name ngx-w-alt-bind-mount -p 3000:80 --mount type=bind,source=/tmp/nginx,target=/usr/share/nginx/html nginx`  \\nand will not create the directory on the host if it doesn\'t exist.\\nThat\'s the main gist about storage when it comes to docker. The thing most often found in the wild is bind mounts with the `-v` syntax and named volumes.\\n\\n#### Installing\\n\\nThere are multiple ways to install docker-compose. From your distributions repositories, from third-party repositories, from the realease binary, from source, from pip but by far my favorite is as a docker container. Take a look [over here](https://docs.docker.com/compose/install/#install-as-a-container) if you\'re interested, otherwise choose the way you prefer to get it installed to your system. After that, we\'re ready to write some YAML.\\n\\n#### Usage\\n\\nTaking advantage of docker-compose is mainly by writing a file that describes how you want your services set up. Just make sure to pay attention to indentation because YAML is very picky about that (be prepared to give the spacebar a proper workout). What images will we work with?\\n\\n## Building Images\\n\\nAll the talk about using docker is good but with kubernetes dominating the industry as far as orchestration, docker finds its home as a way to build images and as a container runtime.\\nHow do you build an image then? It all starts with a Dockerfile.\\n\\n### Dockerfile\\n\\nSimilar to a Makefile but used for docker containers instead, the Dockerfile describes how to build your image. The first statement is `FROM` which specifies which base image to use. Other things you need is at least a little bit of familiarity with the tooling used by the project so you can discern what errors mean. Don\'t be intimidated by that though, we\'ll be going through it step by step. \\n\\n#### Single-stage example build\\n\\nFor our starting example, we\'ll use nginx and the following simple index.html:  \\n```\\n<!DOCTYPE html>\\n<html>\\n\\t<head>\\n\\t\\t<title>First Docker Image</title>\\n\\t</head>\\n\\t<body>\\n\\t\\t<h1>It exists and it works.</h1>\\n\\t</body>\\n</html>\\n```\\nSo we create a new file named Dockerfile and put the following in it  \\n```  \\nFROM nginx:1.17.10-alpine\\n```\\nWe could bind-mount our files but shipping them inside the image is we\'d need if this was a website we were packing so let\'s do it. I\'m making the assumption that index.html is in the current working directory\\n```  \\nFROM nginx:1.17.10-alpine\\nCOPY ./index.html /usr/share/nginx/html/\\n```\\nWithout a port exposed, it won\'t be accessible even if we bind ports to it so let\'s do that next\\n```  \\nFROM nginx:1.17.10-alpine\\nCOPY ./index.html /usr/share/nginx/html/\\nEXPOSE 80\\n```\\nThe final thing we should put in there is what command will be ran when the container starts. Running as a daemon is not desired since it will be in the foreground so we turn that off.\\n```\\nFROM nginx:1.17.10-alpine\\nCOPY ./index.html /usr/share/nginx/html/\\nEXPOSE 80\\nCMD [\\"nginx\\", \\"-g\\", \\"daemon off;\\"]\\n```\\nNow for building the image we can run a simple  \\n`docker build -f Dockerfile .`  \\nto do the job. The `-f` specifies what file to use to build the image and `.` signifies the current working directory as the build context.\\nWe don\'t necessarily have to specify the file every time, if it is named `Dockerfile` it will be used automatically.  \\n\\nThat\'s not fancy enough though. We should probably give it a name and a tag (otherwise it will be tagged with `:latest`)\\n`docker build -t first-site:0.0.1 .`  \\nRunning the old faithful  \\n`docker image ls`  \\nshould reflect that our custom image was built and tagged appropriately.  \\n\\nCongratulations, you just built your first docker image. But things are never this simple, right? We\'re not always going to be working with websites let alone ones that have less than 10 lines of HTML. Let\'s try something a bit more realistic. What about...a microservice written in golang exposing an api centered around a list of coffees?\\n\\n#### Multi-stage golang example build\\n\\nI am going to be using [this](https://github.com/insanitywholesale/microsrv) for demonstration. Ignore the included dockerfile, our main focus now is to understand the steps required to make images. After cloning the project and entering its directory, delete the included Dockerfile (it\'s not as correct as the one we\'re going to make anyway) and make an empty one. Just the same as before, we\'re going to start with a `FROM ` statement.\\n```\\nFROM golang:1.14.2\\n```\\nPicking version 1.14.2 since that is the latest at the time of writing and the code has been tested to work with it.\\nNext, we\'re going to go into the `$GOPATH` directory, in a subdirectory named `src` and then in a subdirectory with our project\'s name. Note that we use `/go/src/microsrv` since `$GOPATH` is resolved to `/go` in this image.\\n```\\nFROM golang:1.14.2\\nWORKDIR /go/src/microsrv\\n```\\nWe could have used the `RUN` statement and done `RUN cd $GOPATH/src/microsrv` but the `WORKDIR` command works at the Dockerfile level meaning that all subsequent commands will use it and it also creates the directory in case it doesn\'t exist already.\\nAfter that, it\'s time to copy over the project files using `COPY`\\n```\\nFROM golang:1.14.2\\nWORKDIR /go/src/microsrv\\nCOPY . .\\n```\\nthis copies the contents of our current working directory outside of the container (project\'s root) into the current working directory inside the container ($GOPATH/src/microsrv)\\nFollowing that, we run the command to download all the required dependencies and source code but not build or install the project (that\'s due to using `-d`). Here the `RUN`statement is used which executes the command after it inside the container.\\n```\\nFROM golang:1.14.2\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\n```\\nOf course in the end we want to build and install the project so let\'s do that\\n```\\nFROM golang:1.14.2\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\n```\\nRight after that is exposing the port, 9090 in this case\\n```\\nFROM golang:1.14.2\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\nEXPOSE 9090\\n```\\nThe last piece missing is the command to be executed\\n```\\nFROM golang:1.14.2\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\nEXPOSE 9090\\nCMD [\\"microsrv\\"]\\n```\\nOn to building the image now  \\n`docker build -t coffee-api:0.0.1 .`\\nand then running and testing it\\n`docker run --rm -d --name coffee-api -p 9090:9090 coffee-api:0.0.1`\\n`curl http://localhost:9090/products`  \\nwhich should return a JSON-formatted object of all the coffees and their public-facing details.\\nThis is all fine and dandy but if we check `docker image ls` we see that the resulting image is about 1GB in size which just won\'t fly. We have to optimize but how? One way is to think of what\'s needed in compile-time compared to run-time. The entire language is not required after the project has been built and not much if any operating-system level tools are required other than for debugging.  \\n\\nTo achive this separation we can use multi-stage builds.\\nThe first step is taking out runtime-specific things out of the build stage.\\nWhat port gets exposed and what command is ran when the container starts is not in the build stage\'s scope so let\'s remove those.\\n```\\nFROM golang:1.14.2\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\n```\\nTime to build the second stage. First we\'ll use an alias for the first stage in order to be able to copy stuff from it.  \\n```\\nFROM golang:1.14.2 as build\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\n```\\nWith that done, let\'s define the second stage inside the same file. We\'ll use busybox, a very small image that has just enough to be usable for our case. Since the default image uses glibc as its C library, we\'ll specify that tag since busybox doesn\'t use it by default.\\n```\\nFROM golang:1.14.2 as build\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\n\\nFROM busybox:glibc\\n```\\nHere is where the alias comes in handy when copying the resulting binary (located at $GOPATH/bin/microsrv) from the first stage\\n```\\nFROM golang:1.14.2 as build\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\n\\nFROM busybox:glibc\\nCOPY --from=build /go/bin/microsrv /\\n```\\nAnd finally we add the two lines that were removed  \\n```\\nFROM golang:1.14.2 as build\\nWORKDIR /go/src/microsrv\\nCOPY . .\\nRUN go get -d -v ./...\\nRUN go install -v ./...\\n\\nFROM busybox:glibc\\nCOPY --from=build /go/bin/microsrv /\\nEXPOSE 9090\\nCMD [\\"/microsrv\\"]\\n```\\nAll that\'s left now is to build (I incremented the version number so the image doesn\'t steal the previous one\'s tagged name but normally you want the docker image version to match the version of the application)\\n`docker build -t coffee-api:0.0.2 .`\\nthen run and test  \\n`docker run --rm -d --name coffee-api -p 9090:9090 coffee-api:0.0.1`\\n`curl http://localhost:9090/products`  \\n\\nIf everything went according to plan, a JSON object with the coffees was returned to you and you\'ve built your first multi-stage docker image (which you should remember to stop using `docker stop coffee-api`). We\'re not done yet though, maybe it\'s time we throw our old pal nginx back into the mix and move from the backend to the frontend.\\n\\n#### Multi-stage reactjs example build\\n\\nNow that our backend is all packed up, time to see how we\'d go about doing the same thing with the frontend. This time we have to interact with nodejs during the build but it\'s not required for runtime. I think you get an idea of what\'s to come so let\'s not hesitate.\\n\\nThe project I\'ll be using for this demonstration is [this](https://gitlab.com/insanitywholesale/reactionary), just a simple one-page counter application. Same as the previous example, we\'ll clone it, change into its directory and delete the included Dockerfile since we\'ll be remaking it from scratch.\\nAs I mentioned, it\'s good to know the project\'s tooling, in this case we need node and npm for building the application but not for running it. We\'ll start with a `FROM` statement to grab the node image but pre-emptively optimize by going with the alpine flavour. The size comparison between the regular version is as follows and should explain why this is a better choice.  \\n```\\n$ docker images | grep node\\nnode                             alpine              0854fcfc1637        2 days ago          117MB\\nnode                             latest              a511eb5c14ec        2 days ago          941MB\\n```\\nComing in at over 8 times the size of the alpine one, the main image is massive and doesn\'t include anything we need and won\'t get otherwise.\\nStarting with our Dockerfile then, we pick the latest (at the time of writing) node image based on the latest alpine version and alias it to `build` since it will be our build stage\\n```\\nFROM node:14.1.0-alpine3.11 as build\\n```\\nWe then change our current working directory to `/app` and move all of our project\'s freshly cloned files in there\\n```\\nFROM node:14.1.0-alpine3.11 as build\\nWORKDIR /app\\nCOPY . .\\n```\\nNow on to getting everything installed and ready for the build. Since it\'s a reactjs website and the scripts that will be run (as defined in package.json) are from the `react-scripts` package (which needs to be installed globally) we will opt for installing that first before the usual `npm install`. Here is the Dockerfile up until now  \\n```\\nFROM node:14.1.0-alpine3.11 as build\\nWORKDIR /app\\nCOPY . .\\nRUN npm install --global react-scripts\\nRUN npm install\\n```\\nTo finish up the build stage one last command is required in order to generate the files that nginx will serve  \\n```\\nFROM node:14.1.0-alpine3.11 as build\\nWORKDIR /app\\nCOPY . .\\nRUN npm install --global react-scripts\\nRUN npm install\\nRUN npm run build\\n```\\nThere we go then. The resulting files will be inside the container in the `/app/build` directory. No instructions for exposing any ports or the starting command we specified since that\'s for the runtime stage. Speaking of which, you might have already guessed what the rest of the Dockerfile will look like. Start with an nginx alpine image, copy over only the necessary files to it from the build stage, open up port 80 and start nginx in foreground mode. Here is the final result\\n```\\nFROM node:14.1.0-alpine3.11 as build\\nWORKDIR /app\\nCOPY . .\\nRUN npm install --global react-scripts\\nRUN npm install\\nRUN npm run build\\n\\nFROM nginx:1.17.10-alpine\\nCOPY --from=build /app/build /usr/share/nginx/html\\nEXPOSE 80\\nCMD [\\"nginx\\", \\"-g\\", \\"daemon off;\\"]\\n```\\nAfter we\'re done with that, we should actually build the image and give it a descriptive tag  \\n`docker build -t reactjs-counters:0.0.1 .`  \\nfollowed up by starting it in order to test\\n`docker run --rm -d --name reactjs-counters -p 80:80 reactjs-counters:0.0.1`\\nand then visit  \\n`http://localhost`  \\nin your browser of choice to see if it works.\\n\\n## Publishing Images\\n\\nWe\'ve made our image and sharing is caring so how do we make it available to the world and where are images stored? The go-to place for getting images is dockerhub, a public docker registry. Docker registries are where images are stored and distributed from. You can also run your own if you wish but that\'s for another time. Right now, we have two images built and ready to be shipped. Well...almost. We could certainly upload them as they are and then try to pull them but we\'d find that we need to specify a tag. That happens because they\'re not tagged as `:latest` which is the default tag. One step at a time though.\\n\\n### DockerHub\\n\\nFirst, you should make an account if you don\'t have one already by going over on the [dockerhub website](https://hub.docker.com/signup) and signing up. Next up, run `docker login` in a terminal to, you guessed it, log in. This will allow you to push images to your account. I already got mine so we\'re ready to start.  \\n\\n### Tagging\\nSince we just finished making our reactjs-based image, let\'s use it here too. Previously we only tagged it as `reactjs-counters:0.0.1` but we need something more now. The format of the image name should be `username/image:tag`. There at least 2 ways to go about this. Either rebuild the image and tag it differently or tag the existing one. I\'ll go over both of them.\\n\\nFirst, let\'s look at the \\"I wish I\'d known sooner\\" method. As we know, images have a unique identifier. This is under the ``IMAGE ID` column in `docker image ls` output. A single image can be tagged with different names. So here is the way we\'d build it with multiple tags, one of them being the properly versioned one and the other one being latest (don\'t forget to substitute `username` with your actual username):  \\n`docker build -t username/reactjs-counters:0.0.1 -t username/reactjs-counters:latest .`  \\nAnd there we have it. Simple enough, ain\'t it? But how about tagging an already existing image? Someone might not fancy rebuilding theirs.\\n\\nThat\'s what the `docker tag` command is for. All we have to do is find the image ID from the output of `docker image ls` and then tag it twice. Here we go then (assuming this is the image ID `7755c1923b8a`):\\n```\\ndocker tag 7755c1923b8a username/reactjs-counters:0.0.1\\ndocker tag 7755c1923b8a username/reactjs-counters:latest\\n```\\n\\n\\n### Pushing\\n\\nAll that\'s left is to `docker push` the image of our choice and make it available so other people can `docker pull` it.  \\n\\n```\\ndocker push username/reactjs-counters:0.0.1\\ndocker push username/reactjs-counters:latest\\n```\\nAnd that\'s it!  \\nWe have successfully taken an application, written a Dockerfile for it, built an image for it and published it to DockerHub!\\n\\n## Outro\\n\\nHopefully you\'ve learned something useful about docker after reading this, I had fun writing it and looking into things that had faded from my memory. Docker is an interesting technology that can be leveraged in many ways to improve development and production workflows everywhere from a single board computer to a fleet of servers in a datacenter. Let me know what you thought about it and I hope you have a good rest of your day."},{"id":"welcome","metadata":{"permalink":"/blog/welcome","source":"@site/blog/engineering/2019-05-28-example.md","title":"Welcome","description":"Example of a blog post.","date":"2019-05-28T00:00:00.000Z","formattedDate":"May 28, 2019","tags":[{"label":"welcome","permalink":"/blog/tags/welcome"}],"readingTime":0.025,"truncated":false,"authors":[{"name":"csgeek","title":"Sample Post","url":"https://github.com/safaci2000","imageURL":"https://avatars3.githubusercontent.com/u/62894?s=460&v=4"}],"frontMatter":{"slug":"welcome","title":"Welcome","author":"csgeek","author_title":"Sample Post","author_url":"https://github.com/safaci2000","author_image_url":"https://avatars3.githubusercontent.com/u/62894?s=460&v=4","tags":["welcome"]},"prevItem":{"title":"Docker Guide Part 1","permalink":"/blog/docker_guide"}},"content":"Example of a blog post."}]}')}}]);